import 'dotenv/config'
import { tool } from '@langchain/core/tools';
import { z } from 'zod';
import { ToolNode } from '@langchain/langgraph/prebuilt';
import { AIMessage } from '@langchain/core/messages';
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { HumanMessage } from "@langchain/core/messages";


import {
    StateGraph,
    MessagesAnnotation,
    END,
    START
  } from "@langchain/langgraph";

const getWeather = tool((input) => {
    if (['ktm', 'Kathmandu'].includes(input.location.toLowerCase())) {
      return 'It\'s 20 degrees and sunny.';
    } else {
      return 'It\'s 35 degrees and sunny.';
    }
  }, {
    name: 'get_weather',
    description: 'Call to get the current weather.',
    schema: z.object({
      location: z.string().describe("Location to get the weather for."),
    })
})

const getCoolestCities = tool(() => {
    return 'namche, ktm';
  }, {
    name: 'get_coolest_cities',
    description: 'Get a list of coolest cities',
    schema: z.object({
      noOp: z.string().optional().describe("No-op parameter."),
    })
})


const tools = [getWeather, getCoolestCities]
const toolNode = new ToolNode(tools)

//ToolNode operates on graph state with a list of messages. 
// It expects the last message in the list to be an AIMessage with tool_calls parameter.
// Let's first see how to invoke the tool node manually:
/*
const messageWithSingleToolCall = new AIMessage({
  content: "",
  tool_calls: [
    {
      name: "get_weather",
      args: { location: "sf" },
      id: "tool_call_id",
      type: "tool_call",
    }
  ]
})

const res = await toolNode.invoke({ messages: [messageWithSingleToolCall] })
console.log(res.messages[0].content) 

/*

/* 
Note that typically you don't need to create AIMessage manually, 
and it will be automatically generated by any LangChain chat model that supports tool calling.
You can also do parallel tool calling using ToolNode 
if you pass multiple tool calls to AIMessage's tool_calls parameter:
*/
/*
const messageWithMultipleToolCalls = new AIMessage({
    content: "",
    tool_calls: [
      {
        name: "get_coolest_cities",
        args: {},
        id: "tool_call_id",
        type: "tool_call",
      },
      {
        name: "get_weather",
        args: { location: "sf" },
        id: "tool_call_id_2",
        type: "tool_call",
      }
    ]
})
  
const res =  await toolNode.invoke({ messages: [messageWithMultipleToolCalls] })
// console.log(res)
console.log(res.messages[0].content)

*/
/*
We'll be using a small chat model from Anthropic in our example. 
To use chat models with tool calling, we need to first ensure that the model 
is aware of the available tools. We do this by calling .bindTools 
method on ChatAnthropic model
*/



const modelWithTools = new ChatGoogleGenerativeAI({
  model: "gemini-1.5-flash",
  temperature: 0,
  apiKey: process.env.GOOGLE_API_KEYy,
}).bindTools(tools);
/*
const responseMessage = await modelWithTools.invoke("what's the weather in ktm?");

console.log(responseMessage.tool_calls);
*/
/* Output:
[
  { name: 'get_weather', args: { location: 'ktm' }, type: 'tool_call' }
]
*/
/*
const response = await toolNode.invoke({ messages: [await modelWithTools.invoke("what's the weather in sf?")] })

console.log(response) 

*/

const toolNodeForGraph = new ToolNode(tools)

const shouldContinue = (state) => {
    const { messages } = state;
    const lastMessage = messages[messages.length - 1];
    if (
      "tool_calls" in lastMessage &&
      Array.isArray(lastMessage.tool_calls) &&
      lastMessage.tool_calls.length
    ) {
      return "tools";
    }
    return END;
};

const callModel = async (state) => {
    const { messages } = state;
    const response = await modelWithTools.invoke(messages);
    return { messages: response };
};

const workflow = new StateGraph(MessagesAnnotation)
  .addNode("agent", callModel)
  .addNode("tools", toolNodeForGraph)
  .addEdge(START, "agent")
  .addConditionalEdges("agent", shouldContinue, ["tools", END])
  .addEdge("tools", "agent");

const app = workflow.compile();

// example with a single tool call
const stream = await app.stream(
    {
      messages: [{ role: "user", content: "what's the weather in ktm?" }],
    },
    {
      streamMode: "values"
    }
);
for await (const chunk of stream) {
    const lastMessage = chunk.messages[chunk.messages.length - 1];
    const type = lastMessage._getType();
    const content = lastMessage.content;
    const toolCalls = lastMessage.tool_calls;
    console.dir({
        type,
        content,
        toolCalls
    }, { depth: null });
}
const streamWithMultiToolCalls = await app.stream(
    {
        messages: [{ role: "user", content: "what's the weather in the coolest cities?" }],
    },
    {
      streamMode: "values"
    }
  )
  for await (const chunk of streamWithMultiToolCalls) {
    const lastMessage = chunk.messages[chunk.messages.length - 1];
    const type = lastMessage._getType();
    const content = lastMessage.content;
    const toolCalls = lastMessage.tool_calls;
    console.dir({
      type,
      content,
      toolCalls
    }, { depth: null });
  }

